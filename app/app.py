import os
import requests
import streamlit as st
from dotenv import load_dotenv
from typing import Dict, Any, List, Tuple

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="å…¬å¸è§„èŒƒä¸ä»£ç çŸ¥è¯†åº“åŠ©æ‰‹",
    page_icon="ğŸ’»",
    layout="wide"
)

# APIç«¯ç‚¹
API_URL = os.getenv("API_URL", "http://localhost:8000")


def query_api(question, clear_history=False, advanced_rag=True):
    """è°ƒç”¨APIè¿›è¡ŒæŸ¥è¯¢"""
    try:
        response = requests.post(
            f"{API_URL}/query",
            json={
                "question": question,
                "clear_history": clear_history,
                "advanced_rag": advanced_rag
            }
        )
        return response.json()
    except Exception as e:
        st.error(f"APIè°ƒç”¨é”™è¯¯: {str(e)}")
        return None


# å°†å±•å¼€å™¨å†…å®¹ç”ŸæˆæŠ½è±¡ä¸ºå•ç‹¬çš„å‡½æ•°
def generate_expander_content(response: Dict[str, Any]) -> List[Tuple[str, str]]:
    """
    æ ¹æ®APIå“åº”ç”Ÿæˆæ‰©å±•å™¨å†…å®¹

    Args:
        response: APIå“åº”å­—å…¸

    Returns:
        åŒ…å«(æ ‡é¢˜, å†…å®¹)å…ƒç»„çš„åˆ—è¡¨
    """
    expanders_content = []

    # å¦‚æœæœ‰æºæ–‡æ¡£ï¼Œå‡†å¤‡æ˜¾ç¤ºå†…å®¹
    if "source_documents" in response and response["source_documents"]:
        source_docs_content = []
        for i, doc in enumerate(response["source_documents"]):
            source_docs_content.append(f"**æº {i + 1}**: {doc.get('metadata', {}).get('source', 'æœªçŸ¥')}")
            source_docs_content.append(f"```\n{doc.get('page_content', 'æ— å†…å®¹')}\n```")
            source_docs_content.append("---")

        expanders_content.append(("æŸ¥çœ‹æºæ–‡æ¡£", "\n".join(source_docs_content)))

    # å¦‚æœæœ‰æ£€ç´¢å…ƒæ•°æ®ï¼Œå‡†å¤‡æ˜¾ç¤ºå†…å®¹
    if "retrieval_metadata" in response and response["retrieval_metadata"]:
        metadata = response["retrieval_metadata"]
        metadata_content = []

        # æ£€ç´¢ç­–ç•¥
        if "strategy_used" in metadata:
            strategy_map = {
                "basic": "åŸºæœ¬æ£€ç´¢",
                "query_rewrite": "æŸ¥è¯¢é‡å†™",
                "decomposition": "æŸ¥è¯¢åˆ†è§£",
                "hyde": "å‡è®¾æ–‡æ¡£æ£€ç´¢",
                "hybrid": "æ··åˆç­–ç•¥"
            }
            strategy = strategy_map.get(metadata["strategy_used"], metadata["strategy_used"])
            metadata_content.append(f"**æ£€ç´¢ç­–ç•¥**: {strategy}")

        # æŸ¥è¯¢åˆ†æ
        if "analysis" in metadata:
            analysis = metadata["analysis"]
            metadata_content.append("**æŸ¥è¯¢åˆ†æ**:")
            complexity_map = {
                "simple": "ç®€å•",
                "medium": "ä¸­ç­‰",
                "complex": "å¤æ‚"
            }
            complexity = complexity_map.get(analysis.get("complexity"), analysis.get("complexity", "æœªçŸ¥"))
            metadata_content.append(f"- å¤æ‚åº¦: {complexity}")
            metadata_content.append(
                f"- éœ€è¦ä»£ç ç¤ºä¾‹: {'æ˜¯' if analysis.get('requires_code_examples') else 'å¦'}")
            metadata_content.append(f"- æŠ€æœ¯æ€§é—®é¢˜: {'æ˜¯' if analysis.get('is_technical') else 'å¦'}")
            if "explanation" in analysis:
                metadata_content.append(f"- ç­–ç•¥é€‰æ‹©ç†ç”±: {analysis.get('explanation')}")

        # å­æŸ¥è¯¢
        if "subquestions" in metadata:
            metadata_content.append("**åˆ†è§£çš„å­æŸ¥è¯¢**:")
            for i, subq in enumerate(metadata["subquestions"]):
                metadata_content.append(f"- å­æŸ¥è¯¢ {i + 1}: {subq}")

        # é‡å†™æŸ¥è¯¢
        if "rewritten_query" in metadata:
            metadata_content.append(f"**é‡å†™åçš„æŸ¥è¯¢**: {metadata['rewritten_query']}")

        # HyDEå‡è®¾æ€§ç­”æ¡ˆ
        if "hypothetical_answer" in metadata:
            metadata_content.append(f"**å‡è®¾æ€§ç­”æ¡ˆ**: {metadata['hypothetical_answer']}")

        expanders_content.append(("æŸ¥çœ‹æ£€ç´¢è¯¦æƒ…", "\n".join(metadata_content)))

    # å¦‚æœæœ‰æ€§èƒ½ç»Ÿè®¡æ•°æ®ï¼Œå‡†å¤‡æ˜¾ç¤ºå†…å®¹
    if "performance" in response and response["performance"]:
        performance = response["performance"]
        perf_content = []

        # æ·»åŠ æ€»æŸ¥è¯¢æ—¶é—´
        if "total_query_time" in performance:
            perf_content.append(f"**æ€»æŸ¥è¯¢æ—¶é—´**: {performance['total_query_time']:.4f}ç§’")

        # æ·»åŠ LLMè°ƒç”¨æ—¶é—´
        if "answer_generation" in performance:
            perf_content.append(f"**LLMç”Ÿæˆå›ç­”æ—¶é—´**: {performance['answer_generation']:.4f}ç§’")

        # æ·»åŠ æ£€ç´¢æ—¶é—´
        if "adaptive_retrieval" in performance:
            perf_content.append(f"**æ£€ç´¢æ—¶é—´**: {performance['adaptive_retrieval']:.4f}ç§’")

        # æ·»åŠ å…¶ä»–å…³é”®æ—¶é—´
        for key, value in performance.items():
            if key not in ["total_query_time", "answer_generation", "adaptive_retrieval"]:
                # æ ¼å¼åŒ–é”®åä»¥æ›´æ˜“è¯»
                readable_key = key.replace("_", " ").title()
                perf_content.append(f"**{readable_key}**: {value:.4f}ç§’")

        expanders_content.append(("æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡", "\n".join(perf_content)))

    return expanders_content


# æ˜¾ç¤ºæ¶ˆæ¯åŠå…¶æ‰©å±•å™¨çš„å‡½æ•°
def display_message(message: Dict[str, Any]):
    """
    æ˜¾ç¤ºå•ä¸ªæ¶ˆæ¯åŠå…¶æ‰©å±•å™¨å†…å®¹

    Args:
        message: æ¶ˆæ¯å­—å…¸ï¼ŒåŒ…å«è§’è‰²ã€å†…å®¹å’Œå¯èƒ½çš„å…ƒæ•°æ®
    """
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”åŒ…å«é™„åŠ ä¿¡æ¯
        if message["role"] == "assistant":
            # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯èƒ½çš„æ‰©å±•å™¨ä¿¡æ¯çš„ä¸´æ—¶å“åº”å¯¹è±¡
            response_data = {
                "source_documents": message.get("source_documents", []),
                "retrieval_metadata": message.get("retrieval_metadata", {}),
                "performance": message.get("performance", {})
            }

            # ç”Ÿæˆå¹¶æ˜¾ç¤ºæ‰©å±•å™¨
            for title, content in generate_expander_content(response_data):
                with st.expander(title):
                    st.markdown(content)


# å¤„ç†é—®é¢˜æäº¤çš„å‡½æ•°
def handle_question_submission(question):
    """å¤„ç†é—®é¢˜æäº¤é€»è¾‘ï¼Œæ·»åŠ åˆ°å†å²å¹¶æŸ¥è¯¢API"""
    # è·å–ä¾§è¾¹æ ä¸­çš„é«˜çº§RAGè®¾ç½®
    use_advanced_rag = st.session_state.get("use_advanced_rag", True)

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": question})

    # æ˜¾ç¤ºåŠ©æ‰‹æ€è€ƒä¸­çŠ¶æ€
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("æ€è€ƒä¸­...")

        # è°ƒç”¨API
        response = query_api(question, advanced_rag=use_advanced_rag)

        if response:
            # æ›´æ–°æ¶ˆæ¯
            answer = response.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
            message_placeholder.markdown(answer)

            # ç”Ÿæˆå¹¶æ˜¾ç¤ºæ‰©å±•å™¨
            for title, content in generate_expander_content(response):
                with st.expander(title):
                    st.markdown(content)

            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "source_documents": response.get("source_documents", []),
                "retrieval_metadata": response.get("retrieval_metadata", {}),
                "performance": response.get("performance", {})
            })
        else:
            message_placeholder.markdown("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ã€‚")
            st.session_state.messages.append({
                "role": "assistant",
                "content": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ã€‚"
            })

    # å¼ºåˆ¶åˆ·æ–°é¡µé¢
    st.rerun()


# æ·»åŠ æ ‡é¢˜
st.title("ğŸ§© å…¬å¸è§„èŒƒä¸ä»£ç çŸ¥è¯†åº“åŠ©æ‰‹")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")

    # æ·»åŠ é«˜çº§RAGè®¾ç½®é€‰é¡¹
    if "use_advanced_rag" not in st.session_state:
        st.session_state.use_advanced_rag = True

    st.session_state.use_advanced_rag = st.checkbox("ä½¿ç”¨é«˜çº§RAGåŠŸèƒ½", value=st.session_state.use_advanced_rag)

    if st.button("æ¸…é™¤å¯¹è¯å†å²"):
        st.session_state.messages = []
        # è°ƒç”¨APIæ¸…é™¤æœåŠ¡å™¨ç«¯å†å²
        query_api("", clear_history=True)
        st.success("å·²æ¸…é™¤å¯¹è¯å†å²")

    st.markdown("---")
    st.markdown("### ğŸ” æç¤ºç¤ºä¾‹")
    example_questions = [
        "FastAPIçš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "Blackæ ¼å¼åŒ–å·¥å…·çš„é»˜è®¤è¡Œé•¿åº¦æ˜¯å¤šå°‘ï¼Ÿ",
        "FastAPIä¸­å¦‚ä½•å®šä¹‰è·¯å¾„å‚æ•°ï¼Ÿ",
        "å¦‚ä½•åœ¨Requestsä¸­è®¾ç½®è¯·æ±‚è¶…æ—¶ï¼Ÿ",
        "å¦‚ä½•ç»“åˆRequestså’Œå¼‚æ­¥ç¼–ç¨‹å®ç°é«˜æ•ˆçš„å¹¶å‘APIè¯·æ±‚å¤„ç†ï¼Ÿ"
    ]

    for q in example_questions:
        if st.button(q):
            # è§¦å‘é—®é¢˜æäº¤å¤„ç†
            handle_question_submission(q)

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    display_message(message)

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # å¤„ç†ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    handle_question_submission(prompt)